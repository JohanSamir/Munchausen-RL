# -*- coding: utf-8 -*-
"""IQN-JAX[Munchausen-MultipleRUNs].ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18lDC-jVX7GTxgWyqp9zIMjCnghXlHHvo
"""

#You should delete the save files to run a new simulation. If this is not done this script will load the previous checkpoints and logs.

#!pip install tensorflow --upgrade


#!git clone https://github.com/kenjyoung/MinAtar.git
#%cd MinAtar
#!pip install .

#!apt install swig
#!pip install box2d box2d-kengz

#!pip install -U dopamine-rl

import numpy as np
import os
#from dopamine.agents.dqn import dqn_agent

import dopamine
from dopamine.discrete_domains import run_experiment
from dopamine.colab import utils as colab_utils
from absl import flags
import gin.tf

import matplotlib
#matplotlib.use('TKAgg')

#import minatar
#minatar.__version__

#import matplotlib
#matplotlib.use('TkAgg')

#from google.colab import drive 
#drive.mount('/content/drive')
#path_or = '/content/drive/My Drive/SaveFiles/Data/Dopamine_github/'
#path = '/content/drive/My Drive/SaveFiles/Data/Dopamine_github/finalresults_I-QN/cartpole/iqn/'
#path = '/content/drive/My Drive/SaveFiles/Data/Dopamine_github/finalresults_I-QN/cartpole/m-dqn/'
#path = '/content/drive/My Drive/SaveFiles/Data/Dopamine_github/finalresults_I-QN/cartpole/m-dqn-stochastic/'
#path = '/content/drive/My Drive/SaveFiles/Data/Dopamine_github/finalresults_I-QN/cartpole/m-dqn-greedy-100/'

#path = '/content/drive/My Drive/SaveFiles/Data/Dopamine_github/finalresults_I-QN/cartpole/rainbow/'
path = '/files_cartpole/iqn_100/'


import sys

#import sys
#sys.path.append(path_or)
from implicit_quantile_agent_new import*
#from dqn_agent_new import*
#from rainbow_agent_new import*

for i in range (1,7):

  LOG_PATH = os.path.join(path, 'dqn_test'+str(i))
  sys.path.append(path)

  def create_random_dqn_agent(sess, environment, summary_writer=None):
    """The Runner class will expect a function of this type to create an agent."""
    #return JaxDQNAgentNew(num_actions=environment.action_space.n)
    #return JaxRainbowAgentNew(num_actions=environment.action_space.n)
    #return JaxxRainbowAgent(num_actions=environment.action_space.n)
    return JaxImplicitQuantileAgentNew(num_actions=environment.action_space.n)
    #return JaxImplicitQuantileAgentNew(num_actions=environment.action_space.n)
  
  gin.parse_config_file('implicit_cartpole.gin')
  #gin.parse_config_file('/content/drive/My Drive/SaveFiles/Data/Dopamine_github/dqn_cartpole.gin')
  #gin.parse_config_file('/content/drive/My Drive/SaveFiles/Data/Dopamine_github/rainbow_cartpole.gin')
  #gin.parse_config_file('/content/drive/My Drive/SaveFiles/Data/Dopamine_github/quantile_cartpoleA.gin')
  #gin.parse_config_file('/content/drive/My Drive/SaveFiles/Data/Dopamine_github/iq_cartpole.gin')

  random_dqn_runner = run_experiment.TrainRunner(LOG_PATH, create_random_dqn_agent)

  print('Will train agent, please be patient, may be a while...')
  random_dqn_runner.run_experiment()
  print('Done training!')